{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35376e1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://10.57.136.24:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [06/Nov/2023 10:07:25] \"OPTIONS /detection HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Nov/2023 10:07:35] \"POST /detection HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Nov/2023 10:07:40] \"OPTIONS /extraction HTTP/1.1\" 200 -\n",
      "`feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\n",
      "127.0.0.1 - - [06/Nov/2023 10:07:57] \"POST /extraction HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Nov/2023 10:13:45] \"OPTIONS /detection HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Nov/2023 10:13:53] \"POST /detection HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Nov/2023 10:13:58] \"OPTIONS /extraction HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Nov/2023 10:14:09] \"POST /extraction HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, flash, request, redirect, url_for, jsonify, send_file, make_response,session\n",
    "from flask_cors import CORS, cross_origin\n",
    "from roboflow import Roboflow\n",
    "import torch\n",
    "import urllib\n",
    "import cv2\n",
    "import base64\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from transformers import TrOCRProcessor, AutoFeatureExtractor, AutoTokenizer, VisionEncoderDecoderModel, VitsModel, VitsTokenizer\n",
    "from gtts import gTTS\n",
    "import re\n",
    "import torchaudio\n",
    "import uuid\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-384\")\n",
    "decoder_tokenizer = AutoTokenizer.from_pretrained(\"urduhack/roberta-urdu-small\")\n",
    "processor =TrOCRProcessor(feature_extractor=feature_extractor, tokenizer=decoder_tokenizer)\n",
    "loaded_model = VisionEncoderDecoderModel.from_pretrained(\"./Saved-Model/\").to(\"cuda\")\n",
    "audio_model = VitsModel.from_pretrained(\"facebook/mms-tts-urd-script_arabic\").to(\"cuda\")\n",
    "audio_tokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-urd-script_arabic\", language = \"urdu\")\n",
    "\n",
    "ALLOWED_EXTENSIONS = {'txt', 'pdf', 'png', 'jpg', 'jpeg', 'gif'}\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app, support_credentials=True)\n",
    "app.config['CORS_HEADERS'] = 'Content-Type'\n",
    "\n",
    "app.secret_key = 'my_secret_key'\n",
    "\n",
    "rf = Roboflow(api_key=\"sMDLRU6MwJA4ONNM61TU\")\n",
    "project = rf.workspace(\"urduocr\").project(\"line-detection-urduocr\")\n",
    "model = project.version(2).model\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "@cross_origin(supports_credentials=True)\n",
    "def hello():\n",
    "    return jsonify({\"method\": \"done\"})\n",
    "\n",
    "@app.route('/detection', methods=['GET', 'POST'])\n",
    "@cross_origin(supports_credentials=True)\n",
    "def detect_lines():\n",
    "    if request.method == 'POST':\n",
    "        file = request.get_json()\n",
    "        f = urllib.request.urlopen(file[\"file\"])\n",
    "        myfile = f.read()\n",
    "        id_user = str(uuid.uuid4())\n",
    "        if f.info()['content-type'].split(\"/\")[0] == \"image\":\n",
    "            myfile = np.array(Image.open(io.BytesIO(myfile)))\n",
    "            cv2.imwrite(f\"{id_user}.jpg\", myfile)\n",
    "            detect = model.predict(f\"{id_user}.jpg\", confidence=10, overlap=30)\n",
    "            data = detect.json()\n",
    "            data['predictions'].sort(key=lambda x: x['y'])\n",
    "            detect.save(f\"{id_user}-save_predict.jpg\")\n",
    "            # Get the image bytes\n",
    "            image_bytes = open(f\"{id_user}-save_predict.jpg\", 'rb').read()\n",
    "            # Encode the image bytes to base64\n",
    "            image_base64 = base64.b64encode(image_bytes).decode()\n",
    "            os.remove(f\"{id_user}-save_predict.jpg\")\n",
    "            return jsonify({\"predicted_image\": image_base64, \"is_image\": True, \"my_data\": data, \"user_id\": id_user})\n",
    "\n",
    "        \n",
    "@app.route('/extraction', methods=['GET', 'POST'])\n",
    "@cross_origin(supports_credentials=True)\n",
    "def extract_text():\n",
    "    if request.method == 'POST':\n",
    "        user_id = request.get_json()[\"user_id\"]\n",
    "        image = cv2.imread(f\"{user_id}.jpg\")\n",
    "        count = 1\n",
    "        data = request.get_json()[\"my_data\"]\n",
    "        generated_texts = []\n",
    "        actual_generated_text = \"\"\n",
    "        text_lines = []\n",
    "        if len(data[\"predictions\"]) == 0:\n",
    "            english_pattern = re.compile(r'[a-zA-Z]')\n",
    "            pixel_values_test1 = processor.feature_extractor(image, return_tensors=\"pt\").pixel_values.to(\"cuda\")\n",
    "            generated_ids_test1 = loaded_model.generate(pixel_values_test1, output_scores=True, return_dict_in_generate=True)\n",
    "            \n",
    "            # Get the confidence score\n",
    "            confidence_scores = torch.exp(generated_ids_test1.sequences_scores)\n",
    "\n",
    "            # Print the confidence score\n",
    "            score = confidence_scores.max().item()\n",
    "            \n",
    "            generated_text_test1 = processor.batch_decode(generated_ids_test1.sequences, skip_special_tokens=True)[0]\n",
    "            generated_text_test1 = re.sub(english_pattern, '', generated_text_test1)\n",
    "            main_text = \"\"\n",
    "            if len(generated_text_test1) > 0:\n",
    "                if generated_text_test1.strip(\" \").startswith(\"(''\") :\n",
    "                    main_text = generated_text_test1.strip(\" \")[3:]\n",
    "                elif generated_text_test1.strip(\" \").startswith(\"(\") :\n",
    "                    main_text = generated_text_test1.strip(\" \").lstrip(\"(\")\n",
    "                elif generated_text_test1.strip(\" \").startswith(\"اور:4]\"):\n",
    "                    main_text = generated_text_test1.strip(\" \")[7:]\n",
    "                elif generated_text_test1.strip(\" \").startswith(\"''\") :\n",
    "                    main_text = generated_text_test1.strip(\" \").lstrip(\"''\")\n",
    "                elif generated_text_test1.strip(\" \").startswith(\"اور\"):\n",
    "                    main_text = generated_text_test1.strip(\" \")[3:]\n",
    "                else:\n",
    "                    main_text = generated_text_test1.strip(\" \")\n",
    "    #                 im_pil\n",
    "    #                 print(generated_text_test1)\n",
    "            else:\n",
    "                main_text = generated_text_test1\n",
    "            generated_texts.append(main_text)\n",
    "            text_lines.append({\"index\": count, \"text\": main_text, \"score\": round(score, 2)})\n",
    "        for i in data[\"predictions\"]:\n",
    "            if i['class'] == \"Line\":\n",
    "                height = i['height']\n",
    "                width = i['width']\n",
    "                x = i['x']\n",
    "                y = i['y']\n",
    "\n",
    "                # Padded ROI\n",
    "#                 roi_x = int(x - (width + 30)/ 2)\n",
    "#                 roi_y = int(y - (height + 30)/ 2)\n",
    "#                 roi_width = int(width + 30)\n",
    "#                 roi_height = int(height + 30)\n",
    "                \n",
    "                roi_x = int(x - (width + 5)/ 2)\n",
    "                roi_y = int(y - (height + 5)/ 2)\n",
    "                roi_width = int(width + 5)\n",
    "                roi_height = int(height + 5)\n",
    "\n",
    "                # Non-Padded ROI\n",
    "#                 roi_x = int(x - (width)/ 2)\n",
    "#                 roi_y = int(y - (height)/ 2)\n",
    "#                 roi_width = int(width)\n",
    "#                 roi_height = int(height)\n",
    "\n",
    "\n",
    "                roi = image[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width]\n",
    "                path = f\"cropped_images/cropped_{count}.jpg\"\n",
    "#                 cropImage_list.append(path)\n",
    "#                 cv2.imwrite(path, roi)\n",
    "#                 roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "#                 im_pil = Image.fromarray(roi).convert('RGB')\n",
    "                cv2.imwrite(path, roi)\n",
    "        \n",
    "                english_pattern = re.compile(r'[a-zA-Z]')\n",
    "                pixel_values_test1 = processor.feature_extractor(roi, return_tensors=\"pt\").pixel_values.to(\"cuda\")\n",
    "                generated_ids_test1 = loaded_model.generate(pixel_values_test1, output_scores=True, return_dict_in_generate=True)\n",
    "\n",
    "                # Get the confidence score\n",
    "                confidence_scores = torch.exp(generated_ids_test1.sequences_scores)\n",
    "\n",
    "                # Print the confidence score\n",
    "                score = confidence_scores.max().item()\n",
    "                \n",
    "                generated_text_test1 = processor.batch_decode(generated_ids_test1.sequences, skip_special_tokens=True)[0]\n",
    "                generated_text_test1 = re.sub(english_pattern, '', generated_text_test1)\n",
    "                main_text = \"\"\n",
    "                if len(generated_text_test1) > 0:\n",
    "                    if generated_text_test1.strip(\" \").startswith(\"(''\") :\n",
    "                        main_text = generated_text_test1.strip(\" \")[3:]\n",
    "                    elif generated_text_test1.strip(\" \").startswith(\"(\") :\n",
    "                        main_text = generated_text_test1.strip(\" \").lstrip(\"(\")\n",
    "                    elif generated_text_test1.strip(\" \").startswith(\"اور:4]\"):\n",
    "                        main_text = generated_text_test1.strip(\" \")[7:]\n",
    "                    elif generated_text_test1.strip(\" \").startswith(\"''\") :\n",
    "                        main_text = generated_text_test1.strip(\" \").lstrip(\"''\")\n",
    "                    elif generated_text_test1.strip(\" \").startswith(\"اور\"):\n",
    "                        main_text = generated_text_test1.strip(\" \")[3:]\n",
    "                    else:\n",
    "                        main_text = generated_text_test1.strip(\" \")\n",
    "        #                 im_pil\n",
    "        #                 print(generated_text_test1)\n",
    "                else:\n",
    "                    main_text = generated_text_test1\n",
    "                generated_texts.append(main_text)\n",
    "                text_lines.append({\"index\": count, \"text\": main_text, \"score\": round(score, 2)})\n",
    "                count+=1\n",
    "                \n",
    "        if len(generated_texts)>0:\n",
    "            actual_generated_text = \"\\n\".join(generated_texts)\n",
    "            \n",
    "\n",
    "        \n",
    "#         audio_inputs = audio_tokenizer(text=actual_generated_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "#         audio_output = audio_model(**audio_inputs).waveform\n",
    "#         torchaudio.save('./save.wav', src=audio_output.cpu().detach(), sample_rate=audio_model.config.sampling_rate)\n",
    "\n",
    "#         tts = gTTS(text=actual_generated_text, lang=\"ur\")\n",
    "#         tts.save(f'./audio_lines.mp3')\n",
    "#         audio_bytes = open('./audio_lines.mp3', 'rb').read()\n",
    "#         audio_base64 = base64.b64encode(audio_bytes).decode('UTF-8')\n",
    "#         with open(\"save.wav\", \"rb\") as file:\n",
    "#             male_audio_output = base64.b64encode(file.read()).decode('UTF-8')\n",
    "        session['is_image'] = False\n",
    "        os.remove(f\"{user_id}.jpg\")\n",
    "#         os.remove('./audio_lines.mp3')\n",
    "#         os.remove('./save.wav')\n",
    "        audio_base64 = None\n",
    "        male_audio_output = None\n",
    "        return jsonify({\"generated_text\": actual_generated_text, \"audio_google\": audio_base64, \"text_lines\": text_lines, \"audio_facebook\" : male_audio_output})\n",
    "        \n",
    "        \n",
    "        \n",
    "app.run(debug=False, host='0.0.0.0', port=5000, threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea4248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import VitsModel, VitsTokenizer\n",
    "# model = VitsModel.from_pretrained(\"facebook/mms-tts-urd-script_arabic\").to(\"cuda\")\n",
    "# tokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-urd-script_arabic\", language = \"urdu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beed426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer(text=\"بنانے کے لیے قائداعظم کی رہنمائی میں مسلمانوں نے بہت محنت کی۔ پاکستان\", return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d92bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = model(**inputs).waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf4cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchaudio\n",
    "# torchaudio.save('./save.wav', src=output.cpu().detach(), sample_rate=model.config.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9033d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba04a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
